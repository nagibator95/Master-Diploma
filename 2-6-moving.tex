\section{План изменения архитектуры}

План изменения архитектуры должен представлять собой 
последовательные шаги для внедрения новой архитектуры в старую систему.

Важно понимать, что сложно внедрить всю архитектуру целиком, и лучше использовать для этого отдельные шаги.

Помимо этого, отдельные шаги позволяют так же протестировать различные системы и приобрести уверенность, 
что итоговая реализация архитектура будет корректно работать и успешно справляться с необходимыми нагрузками.

План переноса архитектуры можно разделить на четыре основные части:

\begin{itemize}
    \item Разворачивание основных систем.
    \item Перенос данных в новые схемы и хранилища.
    \item Пошаговая замена и встраивание различных сервисов в текущую систему.
    \item Полный переход на новую архитектуру.
\end{itemize}

\subsection{Разворачивание основных систем}

Предварительно необходимо развернуть необходимые системы, такие как:

\begin{itemize}
    \item СУБД MongoDB для хранения исходных кодов пользователя и протоколов тестирования.
    \item СУБД Redis для хранения кэшей и в качестве бэкенда для воркеров ejudge-listener и Rmatics.
    \item Rmatics в качестве основной системы;
    \item ejudge-listener для обновления статусов посылок и сбора протоколов;
\end{itemize}

Для разворачивания СУБД MongoDB в CentOS достаточно добавить официальный репозиторий MongoDB и установить необходимый пакет через стандартный менеджер пакетов yum.

Однако опытным путём было выяснено, что стандартный конфигурационный файл
обладал существенным недостатком: он не ограничивал количество потребляемой кэшом СУБД оперативной памяти (оперативное запоминающее устройство, ОЗУ).
Данный недостаток был исправлен добавлением в конфигурационный файл максимального количества потребляемой кэшами СУБД.

MongoDB будет запускаться и управляться стандартным для CentOS способом,
с помощью системы systemd.
Конфигурационный файл systemd (юнит) был автоматически добавлен при установке.

Для разворачивания СУБД Redis нужно установить пакет Extra Packages for Enterprise Linux (EPEL) \cite{redis_install}.
Затем можно будет установить СУБД Redis через стандартный менеджер пакетов yum.

Redis будет запускаться и управляться стандартным для CentOS способом,
с помощью системы systemd.
Конфигурационный файл systemd (юнит) был автоматически добавлен при установке.

Установка реализованных сервисов, таких как ejudge-listener и Rmatics потребудет больше усилий.

Оба сервиса написаны на Python и требуют установки различных Python-пакетов для корректной работы.
Для установки различных окружений был использован стандартный для Python менеджер пакетов -- pip и утилита для управлений окружениями Python virtualenv. Оба сервиса будут работать под управлением стандартной для CentOS системы systemd.

Для удобной установки и дальнейшего обновления сервисов были написаны конфигурационные файлы (роли) с помощью использования технологии Ansible.

Ansible -- система управления конфигурациями, написанная на Python, с использованием декларативного языка разметки для описания конфигураций.
Используется для автоматизации настройки и развертывания программного обеспечения. 
Обычно используется для управления Linux-узлами, но Windows также поддерживается. 
Поддерживает работу с сетевыми устройствами, на которых установлен Python версии 2.4 и выше по SSH или WinRM соединению.

Ansible-роли совершают следующие действия для установки сервисов на целевых серверах:

\begin{itemize}
    \item архивируют исходный код;
    \item доставляют исходный код на сервер;
    \item создают необходимые Python-окружения при помощи virtualenv;
    \item перемещают исходный код в необходимые директории;
    \item при необходимости обновляют необходимые systemd-юниты;
    \item запускают или перезапускают сервисы.
\end{itemize}

\subsection{Перенос данных в новые системы и хранилища}

\label{chap:move_data}
Для того, чтобы новая система начала функционировать,
необходимо было осуществить перенос данных из текущих хранилищ в новые.

Нужно скопировать информацию о посылках из текущих таблиц в таблицу pynfotmatics.runs. 
Также нужно перенести данные с файловой системы в СУБД MongoDB.

Для того, чтобы скопировать информацию о посылках из текущих таблиц, 
был написан скрипт на языке SQL, копирующий данные в pynformatics.runs.

Чтобы не нагружать Информатикс, был создан бэкап СУБД MySQL,
который затем был развёрнут на другом сервере. 
Был запущен SQL-скрипт, и таблица pynformatics.runs наполнилась необходимыми данными.
После этого был создан бэкап отдельной таблицы, pynformatics.runs.
Этот бэкап был перенесён на основной сервер Информатикс, а затем был запущен механизм восстановления данных в нужную таблицу.

Таким образом было перенесено более 15 миллионов посылок.
Однако стоит учесть, что посылки, которые появлялись начиная со времени бэкапа СУБД MySQL из Информатикс и до введения отправки посылок через Rmatics,
в pynformatics.runs не перенесены, и был написан отдельный SQL-скрипт,
добавляющий в pynformatics.runs только недостающие посылки.

Для того, чтобы перенести данные о результатах тестирования и исходных кодах пользователя, 
были предприняты аналогичные действия.

Чтобы не нагружать сайт, бэкап посылок и протоколов был развёрнут на другом сервере.
Был написан скрипт на Python, собирающий протоколы и исходный код, 
и сохраняющий данные в MongoDB. 

После этого СУБД MongoDB на этом сервере была остановлена, 
а блобы базы данных были перенесены на сервер Информатикс.
Затем эти блобы были перенесены в директорию данными MongoDB.

Таким образом было перенесено более 15 миллионов исходных кодов, протоколов и результатов тестирования.
Однако стоит учесть, что данные, которые появлялись начиная со времени бэкапа ФС из Информатикс и до введения отправки посылок через Rmatics,
в MongoDB не перенесены, и был написан отдельный Python-скрипт,
переносящий в MongoDB только недостающие исходные коды, протоколы и результаты тестирования.

\subsection{Пошаговое встраивание сервисов}

Для того, чтобы аккуратно совершить переход на новую архитектуру, 
а так же протестировать различные системы и приобрести уверенность в разработанных решениях, было принято вводить функциональность сервисов постепенно.

Был отмечен важный для такого подхода факт факт: 
сервер тестирования Ejudge готов был обработать двукратное увеличение посылок от пользователей.

Как было рассмотрено в главе \ref{chap:move_data}, 
данные после первичного переноса из бэкапов, начали рассинхронизироваться с актуальной информацией о посылках.

Поэтому было принято решение дублировать отправку посылок: 
py-ручки были изменены таким образом, чтобы при отправке посылки в Ejudge,
послыка также отправлялась бы и в Rmatics.
Rmatics затем так же пересылал эту посылку в Ejudge, 
Очевидно, что идентичные 

Это дало возможность сразу решить проблему рассинхронизации от рассинхронизи